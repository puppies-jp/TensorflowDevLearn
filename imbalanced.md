# ä¸å‡è¡¡ãªãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼

- ã“ã®ãƒšãƒ¼ã‚¸ã§ã¯ä¸å‡è¡¡ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã«å¯¾ã™ã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒæ–¹æ³•ã‚’ã¾ã¨ã‚ã¾ã™ã€‚

- [æ··åŒè¡Œåˆ—(Confusion Matrix)](#Confusion)
- [ROCãƒ—ãƒ­ãƒƒãƒˆ](#ROC)
  - å‡ºåŠ›ã—ãã„å€¤ã‚’èª¿æ•´ã™ã‚‹ã ã‘ã§ãƒ¢ãƒ‡ãƒ«ãŒåˆ°é”ã§ãã‚‹ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®ç¯„å›²ã‚’ä¸€ç›®ã§ç¤ºã™
  2å€¤å•é¡Œãªã©ã§é–¾å€¤ã‚’æ±ºã‚ã‚‹ã“ã¨ãªã©ã«ä½¿ãˆã‚‹ã€‚
- [AUPRCãƒ—ãƒ­ãƒƒãƒˆ](#AUPRC)

---

```python
"""ğŸŒŸ è‰²ã€…ãªãƒ¡ãƒˆãƒªã‚¯ã‚¹"""
METRICS = [
      keras.metrics.TruePositives(name='tp'),
      keras.metrics.FalsePositives(name='fp'),
      keras.metrics.TrueNegatives(name='tn'),
      keras.metrics.FalseNegatives(name='fn'), 
      keras.metrics.BinaryAccuracy(name='accuracy'),
      keras.metrics.Precision(name='precision'),
      keras.metrics.Recall(name='recall'),
      keras.metrics.AUC(name='auc'),
      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve
]
```

- Accuracy: $\frac{\text{true samples}}{\text{total samples}}$
  - æ­£è§£ç‡  
- ã“ã®è¾ºã¯2é …åˆ†é¡ã«å‰²ã‚Šå½“ã¦ã‚‹è©±ã‹ãªï¼Ÿ
  - Precision: $\frac{\text{true positives}}{\text{true positives + false positives}}$
    - positiveã¨åˆ¤å®šã—ãŸå†…æ­£ã—ãåˆ¤å®šã§ããŸå‰²åˆ
  - Recall: $\frac{\text{true positives}}{\text{true positives + false negatives}}$
    - å®Ÿéš›ã®trueã®æ•°ã¨trueåˆ¤å®šã—ãŸæ•°ã®æ¯”
  - AUC:
  - AUPRC:

---

## ã‚¢ãƒ³ãƒ€ãƒ¼ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã€ã‚ªãƒ¼ãƒãƒ¼ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°

- ã‚¢ãƒ³ãƒ€ãƒ¼ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
  - **`å°‘æ•°æ´¾ã®ãƒ‡ãƒ¼ã‚¿ä»¶æ•°`** ã«åˆã†ã‚ˆã†ã«
    **`å¤šæ•°æ´¾ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ ã«æŠ½å‡º`** ã™ã‚‹æ–¹æ³•ã§ã™ã€‚

- ã‚ªãƒ¼ãƒãƒ¼ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
  - **`å°‘æ•°æ´¾ã®ãƒ‡ãƒ¼ã‚¿`** ã‚’ã‚‚ã¨ã«
    **`ä¸è¶³åˆ†ã®ãƒ‡ãƒ¼ã‚¿ã‚’è£œå®Œã™ã‚‹`** ã¨ã„ã†ã‚‚ã®

  - ã‚ªãƒ¼ãƒãƒ¼ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ–¹æ³•1(`tf.data`ã‚’ä½¿ã£ãŸæ–¹æ³•)

  ```python
  BUFFER_SIZE = 100000

  """ğŸŒŸ1 pos,negã ã‘ã§ã‚µãƒ³ãƒ—ãƒ«ã‚’ä½œæˆã™ã‚‹
  """
  def make_ds(features, labels):
      ds = tf.data.Dataset.from_tensor_slices((features, labels))#.cache()
      ds = ds.shuffle(BUFFER_SIZE).repeat()
      return ds
      
  pos_ds = make_ds(pos_features, pos_labels)
  neg_ds = make_ds(neg_features, neg_labels)

  """ğŸŒŸ2 ãã‚Œãã‚Œã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«é‡ã¿ã‚’è¨­å®šã—ã€
         ãƒãƒ¼ã‚¸ã™ã‚‹ã€‚
  """
  resampled_ds = tf.data.Dataset.sample_from_datasets([pos_ds, neg_ds], weights=[0.5, 0.5])
  resampled_ds = resampled_ds.batch(BATCH_SIZE).prefetch(2)
  ```

## <a name=Confusion>æ··åŒè¡Œåˆ—(Confusion Matrix)</a>

- å‚è€ƒã‚µã‚¤ãƒˆ
  - [æ··åŒè¡Œåˆ—](https://qiita.com/TsutomuNakamura/items/a1a6a02cb9bb0dcbb37f#%E7%8C%AB%E3%82%92%E6%8E%A8%E6%B8%AC%E3%81%99%E3%82%8B2-%E5%80%A4%E5%88%86%E9%A1%9E%E3%81%AE%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E3%83%A2%E3%83%87%E3%83%AB%E3%82%92%E4%BE%8B%E3%81%AB%E6%B7%B7%E5%90%8C%E8%A1%8C%E5%88%97%E3%82%92%E7%90%86%E8%A7%A3%E3%81%99%E3%82%8B)

- ä½œã‚Šæ–¹

```python
"""ğŸŒŸ1 ãƒ—ãƒ­ãƒƒãƒˆç”¨é–¢æ•°ã‚’å®šç¾©"""
def plot_cm(labels, predictions, p=0.5):
    cm = confusion_matrix(labels, predictions > p)
    plt.figure(figsize=(5,5))
    sns.heatmap(cm, annot=True, fmt="d")
    plt.title('Confusion matrix @{:.2f}'.format(p))
    plt.ylabel('Actual label')
    plt.xlabel('Predicted label')

    """ğŸŒŸ ã“ã“ã¯attributeãªã®ã§ãªãã¦ã„ã„"""
    print('Legitimate Transactions Detected (True Negatives): ', cm[0][0])
    print('Legitimate Transactions Incorrectly Detected (False Positives): ', cm[0][1])
    print('Fraudulent Transactions Missed (False Negatives): ', cm[1][0])
    print('Fraudulent Transactions Detected (True Positives): ', cm[1][1])
    print('Total Fraudulent Transactions: ', np.sum(cm[1]))

"""ğŸŒŸ2 ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å®Ÿè¡Œã™ã‚‹"""
test_predictions_baseline = 
    model.predict(test_features, batch_size=BATCH_SIZE)

"""ğŸŒŸ3 ãƒ—ãƒ­ãƒƒãƒˆã‚’å®Ÿè¡Œã™ã‚‹"""
plot_cm(test_labels, test_predictions_baseline)
```

![ConfusionMatrix](img/confusionMX.png)

## <a name="ROC">ROCãƒ—ãƒ­ãƒƒãƒˆ</a>

```python

"""ğŸŒŸ1 ROCå‡ºåŠ›é–¢æ•°ã‚’å®šç¾©"""
def plot_roc(name, labels, predictions, **kwargs):
    fp, tp, _ = sklearn.metrics.roc_curve(labels, predictions)
    plt.plot(100*fp, 100*tp, label=name, linewidth=2, **kwargs)
    plt.xlabel('False positives [%]')
    plt.ylabel('True positives [%]')
    plt.xlim([-0.5,20])
    plt.ylim([80,100.5])
    plt.grid(True)
    ax = plt.gca()
    ax.set_aspect('equal')

"""ğŸŒŸ2 predictã‚’å®Ÿè¡Œã™ã‚‹"""
train_predictions_baseline = model.predict(train_features, batch_size=BATCH_SIZE)
test_predictions_baseline = model.predict(test_features, batch_size=BATCH_SIZE)

"""ğŸŒŸ3 å‘¼ã³å‡ºã™ã ã‘
       â€»plt.figureã¨ã‹ã‚„ã£ã¦ãªã„ã“ã¨ã«æ³¨æ„
"""
plot_roc("Train Baseline", train_labels, train_predictions_baseline, color=colors[0])
plot_roc("Test Baseline", test_labels, test_predictions_baseline, color=colors[0], linestyle='--')
plt.legend(loc='lower right');
```

![ROCplot1](img/ROCPlot1.png)

## <a name=AUPRC>AUPRC</a>

```python
"""ğŸŒŸAUPRC"""
def plot_prc(name, labels, predictions, **kwargs):
    precision, recall, _ = sklearn.metrics.precision_recall_curve(labels, predictions)

    plt.plot(precision, recall, label=name, linewidth=2, **kwargs)
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.grid(True)
    ax = plt.gca()
    ax.set_aspect('equal')

plot_prc("Train Baseline", train_labels, train_predictions_baseline, color=colors[0])
plot_prc("Test Baseline", test_labels, test_predictions_baseline, color=colors[0], linestyle='--')

plot_prc("Train Weighted", train_labels, train_predictions_weighted, color=colors[1])
plot_prc("Test Weighted", test_labels, test_predictions_weighted, color=colors[1], linestyle='--')

plt.legend(loc='lower right');
```

![AUPRCPlot](img/AUPRCPlot.png)
