# è»¢ç§»å­¦ç¿’,FineTune,ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°

- [tutorial2](#tutorial2)
  - [x] äº‹å‰è¨“ç·´ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹(è»¢ç§»å­¦ç¿’)ã€‚
  - [x] äº‹å‰è¨“ç·´ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‹ã‚‰æ©Ÿèƒ½ã‚’æŠ½å‡ºã™ã‚‹ã€‚
  - [x] ãƒ¢ãƒ‡ãƒ«ã¸ã®å…¥åŠ›ãŒé©åˆ‡ãªå½¢çŠ¶ã§è¡Œã‚ã‚Œã‚‹ã‚ˆã†ã«ã™ã‚‹ã€‚
  - [x] ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å…¥åŠ›ã®å½¢çŠ¶ã«åˆã‚ã›ãŸã‚‚ã®ã«ã™ã‚‹ã€‚
  - [x] ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ« ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å‡ºåŠ›ãƒ‡ãƒ¼ã‚¿ã‚’ã€ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§æŒ‡å®šã•ã‚ŒãŸå…¥åŠ›ã®å½¢çŠ¶ã«åˆã‚ã›ãŸã‚‚ã®ã«ã™ã‚‹ã€‚

- [è»¢ç§»å­¦ç¿’](#Transfer_FineTune)
- [ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°](#Parameter)

## <a name=Transfer_FineTune> è»¢ç§»å­¦ç¿’ FineTune</a>

- [è»¢ç§»å­¦ç¿’](#Transfer)
- [FineTune](#FineTune)

### <a name=Transfer>è»¢ç§»å­¦ç¿’</a>

```python
# Create the base model from the pre-trained model MobileNet V2

"""ğŸŒŸ ã“ã‚Œã§(160,160) â‡¨ (160,160,3) ã«ãªã‚‹
"""
IMG_SIZE = (160, 160)
IMG_SHAPE = IMG_SIZE + (3,)
base_model = tf.keras.applications.MobileNetV2(
    input_shape=IMG_SHAPE,
    # ãªãœtopã‹?
    # æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®å›³ã§ã¯ã€ä¸‹ã‹ã‚‰ä¸Šã«å‘ã‹ã†ãŸã‚ã€ã€Œä¸Šã€ã«åˆ†é¡ãƒ¬ã‚¤ãƒ¤ãƒ¼ãŒã‚ã‚‹ã€‚
    # è»¢ç§»ï¼FineTuneã§ã¯è‡ªèº«ãŒä½¿ç”¨ã™ã‚‹åˆ†ã«ã¯ä¸è¦ãªåˆ†é¡ãŒ
    # å«ã¾ã‚Œã‚‹ãŸã‚include_top=False ã«ã™ã‚‹ã“ã¨ã§ä¸è¦ãªå±¤ã‚’çœãã‚ˆã†ã«ã—ã¦ã„ã‚‹ã€‚
    include_top=False, # ğŸŒŸä¸Šä½ã®åˆ†é¡ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’å«ã¾ãªã„
    # ğŸŒŸimageNet(å¤šå½©ãªã‚«ãƒ†ã‚´ãƒªã‚’æŒã¤ç ”ç©¶ç”¨ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ)
    weights='imagenet' 
    )
```

```python
""" ğŸŒŸ ã“ã®ã‚ˆã†ã«ã™ã‚‹ã“ã¨ã§ã€å–å¾—ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã‚ˆã£ã¦å¤‰æ›´ã§ããªãã™ã‚‹ã€‚
"""
base_model.trainable = False
```

```python

"""ğŸŒŸ ã“ã‚“ãªæ„Ÿã˜ã§ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µå±¤ã‚’ãƒ¢ãƒ‡ãƒ«ã«çµ„ã¿è¾¼ã‚€ã“ã¨ãŒã§ãã‚‹ã€‚
     trainingã§ã®ã¿æœ‰åŠ¹ã«ãªã‚‹ã‚‰ã—ã„
"""
data_augmentation = tf.keras.Sequential([
  tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),
  tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),
])

"""ğŸŒŸ MobileNetã¯ãƒ”ã‚¯ã‚»ãƒ«å€¤[-1,1]ã‚’æƒ³å®šã—ãŸãƒ¢ãƒ‡ãƒ«ã®ãŸã‚ã€
    ã€€ã“ã®ã‚ˆã†ã«ã—ã¦modelã®ãƒ¬ã‚¤ãƒ¤ãƒ¼ã«å…¥ã‚Œã‚‹ã“ã¨ã§ã€ãƒªã‚¹ã‚±ãƒ¼ãƒ«ã§ãã‚‹ã€‚
"""
# ğŸŒŸ ã“ã‚Œã§ã‚‚ä»£ç”¨å¯
# rescale = tf.keras.layers.experimental.preprocessing.Rescaling(1./127.5, offset= -1)
preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input

inputs = tf.keras.Input(shape=(160, 160, 3))
x = data_augmentation(inputs) # ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µå±¤
x = preprocess_input(x) # å…¥åŠ›å±¤
# ğŸŒŸã€€MobileNet(å‡ºåŠ›ã¯(5, 5, 1280)ã§å‡ºåŠ›ã•ã‚Œã‚‹
x = base_model(x, training=False) 
x = global_average_layer(x) # poolingå±¤
x = tf.keras.layers.Dropout(0.2)(x)
outputs = prediction_layer(x) # å‡ºåŠ›å±¤
model = tf.keras.Model(inputs, outputs)
```

### <a name=FineTune>FineTune</a>

- è»¢ç§»å­¦ç¿’ã§ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ã•ã‚‰ã«å‘ä¸Šã•ã›ã‚‹æ–¹æ³•ã® 1 ã¤ã«ã€è¿½åŠ ã—ãŸåˆ†é¡å™¨ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¨ä¸¦è¡Œã—ã¦ã€äº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®æœ€ä¸Šä½ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®é‡ã¿ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆã¾ãŸã¯ã€Œãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã€ï¼‰ã™ã‚‹ã¨ã„ã†ã‚‚ã®ãŒã‚ã‚Šã¾ã™ã€‚

  - ğŸŒŸ **äº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸å¯ã«è¨­å®šã—ã€æœ€ä¸Šä½ã®åˆ†é¡å™¨ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ãŸå¾Œã«è¡Œã†ã‚ˆã†ã«ã—ã¦ãã ã•ã„ã€‚** äº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ä¸Šã«ãƒ©ãƒ³ãƒ€ãƒ ã«åˆæœŸåŒ–ã•ã‚ŒãŸåˆ†é¡å™¨ã‚’è¿½åŠ ã—ã¦ã™ã¹ã¦ã®ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’çµåˆãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã‚ˆã†ã¨ã™ã‚‹ã¨ã€
  `ï¼ˆåˆ†é¡å™¨ã‹ã‚‰ã®ãƒ©ãƒ³ãƒ€ãƒ ãªé‡ã¿ã«ã‚ˆã‚Šï¼‰`
  **`å‹¾é…ã®æ›´æ–°è¦æ¨¡ãŒå¤§ãã™ãã¦`**ã€
  `äº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãŒå­¦ç¿’ã—ãŸã“ã¨ã‚’å¿˜ã‚Œã¦ã—ã¾ã„ã¾ã™`

```python

"""ğŸŒŸ ã“ã“ã‚’trueã«ã™ã‚‹ã“ã¨ã§ã€
    ã€€base_modelã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã§ãã‚‹çŠ¶æ…‹ã«ã™ã‚‹ã€‚ 
"""
base_model.trainable = True

# Let's take a look to see how many layers are in the base model
print(
  "Number of layers in the base model: ", 
  # ğŸŒŸ ã“ã†ã™ã‚‹ã“ã¨ã§ã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ¬ã‚¤ãƒ¤ãƒ¼æ•°ãŒç¢ºèªã§ãã‚‹ã€‚
  len(base_model.layers))

"""ğŸŒŸ ä¸‹ã®ãƒ¬ã‚¤ãƒ¤ãƒ¼(å…¥åŠ›å±¤)å´ã‹ã‚‰100ã®ãƒ¬ã‚¤ãƒ¤ãƒ¼
      ã¾ã§ã®é‡ã¿ã‚’å¤‰æ›´ã§ããªãã™ã‚‹ã€‚
"""
# Fine-tune from this layer onwards
fine_tune_at = 100 

# Freeze all the layers before the `fine_tune_at` layer
for layer in base_model.layers[:fine_tune_at]:
  layer.trainable =  False

"""ğŸŒŸ è¨­å®šå¾Œã¯ãƒ“ãƒ«ãƒ‰ã™ã‚‹ã“ã¨
"""
model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),
              optimizer = tf.keras.optimizers.RMSprop(lr=base_learning_rate/10),
              metrics=['accuracy'])

```

- å­¦ç¿’ã§ãã‚‹ãƒ¬ã‚¤ãƒ¤ãƒ¼ã¯ä»¥ä¸‹ã®ã‚ˆã†ã«ã—ã¦èª¿ã¹ã‚‰ã‚Œã‚‹

```python
len(model.trainable_variables)
```

## <a name=Parameter>Hyperparameters tuning</a>
