# 00\_ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰ã¨è¨“ç·´

## å­¦ã¶ã¹ãé …ç›®ã¯ä»¥ä¸‹

- TensorFlow2.0 ä»¥é™ã‚’ä½¿ç”¨ã™ã‚‹ã€‚

- [tutorial1](#tutorial1)

  - [ ] TensorFlow ã‚’ä½¿ç”¨ã—ã¦æ©Ÿæ¢°å­¦ç¿’(ML)ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰ã€ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã€è¨“ç·´ã‚’è¡Œã†ã€‚
  - [ ] ãƒ‡ãƒ¼ã‚¿ã‚’å‰å‡¦ç†ã—ã¦ãƒ¢ãƒ‡ãƒ«ã§ä½¿ç”¨ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ã€‚
  - [ ] ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦çµæœã‚’äºˆæ¸¬ã™ã‚‹ã€‚
  - [ ] è¤‡æ•°ã®å±¤ã§æ§‹æˆã•ã‚Œã‚‹ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã™ã‚‹ã€‚
  - [ ] äºŒé …åˆ†é¡ã®ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã—ã¦è¨“ç·´ã™ã‚‹ã€‚
  - [ ] å¤šé …åˆ†é¡ã®ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã—ã¦è¨“ç·´ã™ã‚‹ã€‚

- [tutorial2](#tutorial2)

  - [ ] äº‹å‰è¨“ç·´ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹(è»¢ç§»å­¦ç¿’)ã€‚
  - [ ] äº‹å‰è¨“ç·´ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‹ã‚‰æ©Ÿèƒ½ã‚’æŠ½å‡ºã™ã‚‹ã€‚
  - [ ] ãƒ¢ãƒ‡ãƒ«ã¸ã®å…¥åŠ›ãŒé©åˆ‡ãªå½¢çŠ¶ã§è¡Œã‚ã‚Œã‚‹ã‚ˆã†ã«ã™ã‚‹ã€‚
  - [ ] ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å…¥åŠ›ã®å½¢çŠ¶ã«åˆã‚ã›ãŸã‚‚ã®ã«ã™ã‚‹ã€‚
  - [ ] ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ« ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å‡ºåŠ›ãƒ‡ãƒ¼ã‚¿ã‚’ã€ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§æŒ‡å®šã•ã‚ŒãŸå…¥åŠ›ã®å½¢çŠ¶ã«åˆã‚ã›ãŸã‚‚ã®ã«ã™ã‚‹ã€‚

- [tutorial3](#tutorial3)

  - [ ] ãƒ‡ãƒ¼ã‚¿ã®ä¸€æ‹¬èª­ã¿è¾¼ã¿ã«ã¤ã„ã¦ç†è§£ã—ã¦ã„ã‚‹
  - [ ] ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’ä½¿ç”¨ã—ã¦ã€è¨“ç·´ã‚µã‚¤ã‚¯ãƒ«ã®çµ‚äº†ã‚’å‘¼ã³å‡ºã™ã€‚
  - [ ] è¤‡æ•°ã®ã‚½ãƒ¼ã‚¹ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ç”¨ã™ã‚‹ã€‚
  - [ ] è¤‡æ•°ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ(json ã‚„ csv ãªã©)ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ç”¨ã™ã‚‹ã€‚
  - [ ] tf.data.datasets ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ç”¨ã™ã‚‹ã€‚

- [éå­¦ç¿’](#OverFitting)

  - [ ] è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ãƒ—ãƒ­ãƒƒãƒˆã®æå¤±ã¨ç²¾åº¦ã‚’ç¢ºèªã™ã‚‹ã€‚
  - [ ] æ‹¡å¼µã‚„ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆãªã©ã®éå‰°é©åˆã‚’é¿ã‘ã‚‹ãŸã‚ã®æˆ¦ç•¥ã‚’å‰²ã‚Šå‡ºã™ã€‚

---

## <a name="tutorial1">tutorial1</a>

## <a name="tutorial2">tutorial2</a>

## <a name="tutorial3">tutorial3</a>

---

## <a name="OverFitting">éå­¦ç¿’</a>

### éå­¦ç¿’ã®å¯¾ç­–ã«ä»¥ä¸‹ãŒæœ‰åŠ¹ã¨è¨€ã‚ã‚Œã¦ã„ã‚‹ã€‚

- [ ] è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚’å¢—ã‚„ã™
- [ ] data æ‹¡å¼µã‚’å®Ÿè¡Œ
- [x] [dropout å±¤è¿½åŠ (**ãƒ¢ãƒ‡ãƒ«å´ã®æ”¹å–„ç­–**)](#dropOut)
- [x] [network ã®å®¹é‡ã‚’æ¸›ã‚‰ã™(**ãƒ¢ãƒ‡ãƒ«å´ã®æ”¹å–„ç­–**)](#SmallModel)
- [ ] é‡ã¿ã®æ­£å‰‡åŒ–(L1 æ­£å‰‡åŒ–ã€L2 æ­£å‰‡åŒ–ãªã©ã‚’ã—ã¦éå­¦ç¿’ã‚’é˜²ã)
- [ ] ãƒãƒƒãƒæ­£è¦åŒ–

---

- <a name="dropOut">dropout å±¤è¿½åŠ (**ãƒ¢ãƒ‡ãƒ«å´ã®æ”¹å–„ç­–**)</a>

  - **è¨“ç·´æ™‚**ã«å±¤ã‹ã‚‰å‡ºåŠ›ã•ã‚ŒãŸç‰¹å¾´é‡ã«å¯¾ã—ã¦ãƒ©ãƒ³ãƒ€ãƒ ã«ã€Œãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆï¼ˆã¤ã¾ã‚Šã‚¼ãƒ­åŒ–ï¼‰ã€ã‚’è¡Œã†ã‚‚ã®`ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆç‡`ã¯æ¦‚ã­ 0.2 ~ 0.5 ãŒç›®å®‰ã¨è¨€ã‚ã‚Œã¦ã„ã‚‹ã€‚

  ```python
  # ğŸŒŸ ä½¿ã„æ–¹ ã“ã‚Œã‚’ãƒ¢ãƒ‡ãƒ«ã®å±¤ã«è¿½åŠ ã—ã¦ã„ãã ã‘ã€‚
  keras.layers.Dropout(0.5),
  ```

- <a name="SmallModel">network ã®å®¹é‡ã‚’æ¸›ã‚‰ã™(**ãƒ¢ãƒ‡ãƒ«å´ã®æ”¹å–„ç­–**)</a>

  - ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ãŒå¤šã„ã¨ä½™è¨ˆãªæ¡ä»¶ã«å¼•ã£ã‹ã‹ã‚‹ã‚ˆã†ã«ãªã‚Šã€å¢—ãˆã™ãã‚‹ã“ã¨ã§æ±åŒ–æ€§èƒ½ãŒä¸‹ãŒã£ã¦ã„ã(test ãƒ‡ãƒ¼ã‚¿ã§ã¯é«˜ã„æ­£è§£ç‡ã«ã‚‚é–¢ã‚ã‚‰ãšã€validation check ã«ã¦ä½ã„ã‚¹ã‚³ã‚¢ãŒå‡ºã¦ã—ã¾ã†ã€‚(**éå­¦ç¿’**))
  - ã‚»ã‚ªãƒªãƒ¼ã¨ã—ã¦å°ã•ã„ãƒ¢ãƒ‡ãƒ«ã€å¤§ãã„ãƒ¢ãƒ‡ãƒ«ã®ä¸åº¦ã„ã„ã¨ã“ã‚ã‚’æ¢ã™å¿…è¦ãŒã‚ã‚‹ã€‚

- ä»¥ä¸‹ã«ä¾‹ã‚’ç¤ºã™ã€‚

```python
# -------------------------------------------- #
# ğŸŒŸã€€æ™®é€šã®ãƒ¢ãƒ‡ãƒ«
baseline_model = keras.Sequential([
    # `.summary` ã‚’è¦‹ã‚‹ãŸã‚ã«`input_shape`ãŒå¿…è¦
    keras.layers.Dense(16, activation='relu', input_shape=(NUM_WORDS,)),
    keras.layers.Dense(16, activation='relu'),
    keras.layers.Dense(1, activation='sigmoid')
])

baseline_model.compile(optimizer='adam',
                       loss='binary_crossentropy',
                       metrics=['accuracy', 'binary_crossentropy'])

baseline_model.summary()
baseline_history = baseline_model.fit(train_data,
                                      train_labels,
                                      epochs=20,
                                      batch_size=512,
                                      validation_data=(test_data, test_labels),
                                      verbose=2)

# -------------------------------------------- #
# ğŸŒŸã€€å°ã•ã„ãƒ¢ãƒ‡ãƒ«
smaller_model = keras.Sequential([
    keras.layers.Dense(4, activation='relu', input_shape=(NUM_WORDS,)),
    keras.layers.Dense(4, activation='relu'),
    keras.layers.Dense(1, activation='sigmoid')
])

smaller_model.compile(optimizer='adam',
                      loss='binary_crossentropy',
                      metrics=['accuracy', 'binary_crossentropy'])

smaller_model.summary()

smaller_history = smaller_model.fit(train_data,
                                    train_labels,
                                    epochs=20,
                                    batch_size=512,
                                    validation_data=(test_data, test_labels),
                                    verbose=2)
# -------------------------------------------- #
# ğŸŒŸã€€å¤§ãã„ãƒ¢ãƒ‡ãƒ«
bigger_model = keras.models.Sequential([
    keras.layers.Dense(512, activation='relu', input_shape=(NUM_WORDS,)),
    keras.layers.Dense(512, activation='relu'),
    keras.layers.Dense(1, activation='sigmoid')
])

bigger_model.compile(optimizer='adam',
                     loss='binary_crossentropy',
                     metrics=['accuracy','binary_crossentropy'])

bigger_model.summary()
bigger_history = bigger_model.fit(train_data, train_labels,
                                  epochs=20,
                                  batch_size=512,
                                  validation_data=(test_data, test_labels),
                                  verbose=2)
# -------------------------------------------- #


# ğŸŒŸ å¤§ä¸­å°ã®ãƒ¢ãƒ‡ãƒ«ã®binary_crossentropy,epochã‚’è¡¨ç¤ºã™ã‚‹é–¢æ•°
def plot_history(histories, key='binary_crossentropy'):
    plt.figure(figsize=(16,10))

    for name, history in histories:
        val = plt.plot(history.epoch, history.history['val_'+key],
                        '--', label=name.title()+' Val')
        plt.plot(history.epoch, history.history[key], color=val[0].get_color(),
             label=name.title()+' Train')

    plt.xlabel('Epochs')
    plt.ylabel(key.replace('_',' ').title())
    plt.legend()

    plt.xlim([0,max(history.epoch)])

# ğŸŒŸãƒ¢ãƒ‡ãƒ«ã®histryã‚’æ¸¡ã™
plot_history([('baseline', baseline_history),
              ('smaller', smaller_history),
              ('bigger', bigger_history)])

```

- å¤§ã€ä¸­ã€å°ãƒ¢ãƒ‡ãƒ«ã®å®Ÿè¡Œçµæœ

  - Baseline ã¨ Bigger ã® train,val ãŒæ—©ã€…ã«ä¹–é›¢ã—ã¦éå­¦ç¿’ã‚’èµ·ã“ã—ã¦ã„ã‚‹ã“ã¨ãŒåˆ†ã‹ã‚‹ã€‚
    ![OverFit.png](OverFit.png)

- [ ] é‡ã¿ã®æ­£å‰‡åŒ–(L1 æ­£å‰‡åŒ–ã€L2 æ­£å‰‡åŒ–ãªã©ã‚’ã—ã¦éå­¦ç¿’ã‚’é˜²ã)
- [ ] ãƒãƒƒãƒæ­£è¦åŒ–
- [ ] è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚’å¢—ã‚„ã™
